\section{\acs*{SPOR} security analysis}%
\label{spor-security}

\paragraph*{If Eve is in the layers}

\sonja{will motivate using the survey/taxonomy}
The security of SphinxES rests on the fact that the message must pass at least 
one honest node.
Phrasing it in terms of what the adversary~Eve must accomplish, she must ensure 
that the message passes through an adversarial node.
Now that we have some node selection, we can reason about the likelihood of 
that.

The probability of successful attack is proportional to Eve's size in the 
network, \ie \(q_A = \frac{|\devices_A|}{|\devices|}\).
\commentDaniel{Check that we still use the \(\devices_i\) notation for the 
devices in \(i\)'s squad.}
If we assume that \(\GetNode\) returns nodes with close to the uniform 
distribution, then the \(\nu w_L\) nodes selected is expected to contain \(q_A 
\nu w_L\) nodes controlled by Eve.
If \(q_A \nu w_L < \nu\), then Eve is not expected to be present on every layer 
of the route.

Considering how \ac{SPOR} distributed the \(\nu w_L\) selected nodes, Eve's 
best strategy is to have high-availability nodes --- assume that 
\(\avail[\devices_E] = 1\) for all Eve's devices \(\devices_E\).
This way, Eve's devices will be distributed evenly across all layers (provided 
she controls enough of the selected devices).

To link Alice and Bob, Eve must be chosen in the first layer and the route must 
contain the maximum number of layers~\(r\).
(Remember, we chose \(\nu+1\leq r\) in \cref{SphinxEScreate}.)
The probability for Eve to be chosen in the first layer will be 
\(\frac{q_A}{w_L}\) (for a passive adversary and \(1\) for an active).
If one of her devices is chosen in the first layer, then she can choose one of 
her own devices in the next layer.
If she is present on every layer, she can ensure she relays the message all the 
way to Bob.
In summary, her probability of success is \(
  \frac{1}{w_L} (1-(1-q_A)^{(w_L-1) \nu +1})
\) (or without the \(\frac{1}{w_L}\) factor for an active adversary), which can 
be compared to \((q_A)^\nu\) for classical \ac{OR} (for both active and passive 
adversaries).

However, Eve can only be certain that she has relayed the message from Alice to 
Bob if \(\nu+1 = r\), \ie she receives the message from Alice, relays it 
\(r-1\) times and lastly sends it to Bob.
If \(\nu+1 = r-1\), then Eve learns that either Alice must be the sender or Bob 
must be the recipient.
(This is due to the indistinguishability and unlinkability properties of the 
ideal functionality.)
If \(\nu+1 \leq r-2\), then Eve cannot certainly tell whether Alice and Bob are 
end points of simply honest relays for someone else.

That reasoning is only valid when there is more than one node in a layer.
If Eve learns that there is only one node in the next layer, it is likely the 
recipient node.

\paragraph*{Privacy of \(\GetNode\)}

The \(\GetNode\) algorithm must be privacy preserving.
Consider the following scenario.
Alice requests a set of peers, say \(\{d_0, \dotsc, d_{n-1}\}\).
If \(d_i\) interacts in each sampling operation resulting in \(d_i\) being in 
the sample, then \(d_i\) can generate a new public key \(\pk_d^{(j)}\) for each 
sample \(j\).
This means that, if Alice sampled \(d_i\), she knows the public key 
\(\pk_i^{(j)}\), and if \(d_i\) knows it is included in Alice's sample, then it 
will also know a route belongs to Alice whenever \(\pk_i^{(j)}\) is used to 
encrypt the header.
(This follows from the fact that the ideal functionality is source-routed.)
\Ie every node on Alice's route would know that Alice is either the source 
(forward header) or the destination (reply header).

\paragraph*{Distributions in layers}

The output of Alice's query to \(\GetNode\) must only be learned by Alice.
Again, Alice requests a set of peers~\(\{d_0, \dotsc, d_{\nu w_L}\}\).
Say that Eve observes all of Alice's requests.
Now, both Alice and Eve can compute the output of \(\CreateLayers\) 
(deterministic).
Now, if Eve is on that path, say in layer~\(L_i\), she can recognize Alice's 
onions by the composition of the next layer~\(L_{i+1}\).
The likelihood that Bob has a layer \(L_j = L_{i+1}\) is small.
Consider normal onion routing, there the probability that Alice and Bob both 
chose node \(N\) is \(\frac{1}{|\devices|}\).
Here, however, it is \((\frac{1}{|\devices|})^{w_L}\), for large sets of 
devices~\(\devices\).

Consider a node controlled by Eve.
Given the low probability of \(\frac{1}{|\devices|^{w_L}}\) that a combination 
of nodes appear as a layer, the combination Alice's own devices in the final 
layer will have a higher probability of appearing.
Thus, any more frequently appearing combination of nodes is with high 
likelihood the recipient devices of a user.
(This is all the more true when there is only one device in a layer.)

\paragraph*{Device unlinkability}

Alice sends the message \(m\) to Bob during the time interval 
\(\interval{t_0}{t_1}\).
We denote the set of Alice's devices as \(\devices_A\) and Bob's as 
\(\devices_B\).
Bob wants to compute an estimate \(\hat \devices_A\) which is as close to 
\(\devices_A\) as possible.

At this point, Bob knows that \emph{at least one} of Alice's devices must have 
been online at any given time in \(\interval{t_0}{t_1}\).
We can also assume that Bob knows all data from the \ac{RPS}, \ie the \((d, 
\pk_d, a_d)\) tuple (see \cref{SPOR}) of \emph{every device~\(d\) that was 
online at some point during \(\interval{t_0}{t_1}\)}.
Let \(\A_{\interval{t_0}{t_1}}\subseteq \N\times \G^*\times \interval{0}{1}\) 
denote the set of those tuples.
Thus Bob can approximate \(\devices_A\) by \(\hat \devices_A \gets 
\A_{\interval{t_0}{t_1}}\cap \devices_B\).

When Alice and Bob interact the next time, either Alice sends a message \(m'\) 
to Bob or Bob sends a file \(m'\) to Alice, then Bob can do the same again:
\(\hat \devices_A' \gets \A_{\interval{t_0'}{t_1'}} \cap \devices_B\).
If at least one of \(d, \pk_d, a_d\) remains constant, Bob can use that to 
improve his approximation.
Say that \(a_d\) remains constant.
Then Bob can improve his approximation to \(
  \hat \devices_A \cap_{a_d} \hat \devices_A',
\) where \(\cap_{a_d}\) is the intersection which only considers the attribute 
\(a_d\).
Even if \(a_d\) is not constant, its variation might stay inside some 
\(\epsilon\)-neighbourhood, and if \(\epsilon\) is small enough, \(a_d\) might 
still be used to distinguish Alice.
The same applies for \(d\) and \(\pk_d\).

With an inaccurate availability function~\(\avail\) (\eg \(k\)-anonymous, as 
mentioned above) this will not be a problem as there will be many others (as 
the system scales) that share the same availability distribution.
The public key~\(\pk\) can be refreshed regularly.
The main problem is any persistent identifier (address) \(d\).


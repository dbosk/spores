\subsection{The \squad Overlay} 
\label{sec:squad_overlay}

At the root of \name is predictive routing, based on the concept of Probabilistic Onion Routes (POR).
To create PORs, as a device's availability strongly depends on the activity of its owner,
 a user's devices (her \squad) must predict the future behavior of their owner. 
However, one device, belonging to an \squad, can only predict its probability to stay online in the near future
if it has a global knowledge of the user behavior over the other devices of the \squad it belongs to.
To reach this aim, \name relies on a overlay, named thereafter the \squad overlay, to share the user's behavior among devices of its \squad.

%By sharing information among themselves, a user's devices (her \emph{squad}) can model her behavior.

%In this section, we only take interest in one user (called Alice) and her \squad.

% Each of Alice's (and Bob's) devices will keep track of its own online and 
% offline behavior.
% They will use a protocol like Sprinkler~\cite{luxey:hal-01704172} to learn about 
% each other's online--offline behavior.
% \commentDaniel{Is that correct?}
% This allows Alice's device swarm to infer a behavioral model for the device 
% swarm and do internal scheduling based on the probability of being online.


\subsubsection{Sharing the user's behavior} % (fold)
\label{sub:sharing_knowledge}

%Online devices want to know whether they are likely to stay online in the near future.
taken separately, each device can only get local observations, such as when its user used it, and mobility information if it is a handheld device.
If all these local observations can be combined, a device can infer a refined model of the userâ€™s behavior to predict its future activity in an accurate manner. To build such a sequence of observations, 
%a sequence of the user's behavior that is far more complete.
%For instance, the probability that Alice uses her home computer and workstation simultaneously is null: these devices are too far apart.
the \squad overlay leverages on a probabilistic dissemination protocol, \textsc{Sprinkler}~\cite{luxey:hal-01704172}.
it allows one's devices to inform one another every time the user performs an action.
In our previous work~\cite{luxey:cascade}, we showed that \textsc{Sprinkler} is resilient to devices churn: 
devices let each other know of what they have missed while offline.
We thus employ \textsc{Sprinkler} to disseminate the user's activity to its \squad.

% Each device initially only knows when it is connected, which is not sufficient to make reliable predictions on whether it is likely to stay online.
% If they knew the other devices' connection and disconnection times, they 
% To make a model of the user's behavior, they need to know the whole observation sequence $O$: which device is online at each time step.
% To do so, they employ a probabilistic dissemination protocol, 
% \textsc{Sprinkler}~\cite{luxey:hal-01704172}.
% This allows devices to gossip any new connection information to random peers in 
% the local swarm, ensuring that all devices know the full observation sequence 
% with a very high probability.
% \textsc{Sprinkler} has shown resilient to device churn~\cite{luxey:cascade}, and 
% is thus perfectly suited for our purpose, where a user's devices often 
% disconnect and reconnect. 

% subsection sharing_knowledge (end)

% \subsubsection{Other uses of the Squad Overlay} % (fold)
% \label{ssub:other_uses_of_the_squad_overlay}

\paragraph*{Other uses of the \squad Overlay} In addition to user's behavior, devices use the \squad overlay for several purposes. Firstly, they share files location: when Alice wants to share a file $f$ that resides on her home computer, using her smartphone as the exchange initiator, her smartphone knows where $f$ is located and can create the route accordingly. 
Secondly, each device is also informed of its user's ongoing file transfers (which serves the next purpose).
Finally, because devices can receive messages on behalf of their fellow squad members to ensure reception despite the proper recipient being offline, 
one's devices can forward messages among the \squad.

% \david{the following paragraph is not clear at all }
% \name knows two message types (as will be covered in~\ref{sec:file_exchange}): file chunk, and acknowledgment.
% Alice typically wants to receive a file on one particular device; respectively, only one of her devices is interested in acknowledging reception of the file chunks it is sending. \david{what is the relationship with \squad Overlay?}
% However, \name allows all \squad members to receive messages destined to Alice.
% Thus, the third complementary purpose of the \Squad Overlay is to relay messages among the squad: when a message is not destined to the device that received it, the receiver forwards the message to its final destination.
% \david{and then?}

\subsubsection{Modeling the user's behavior}
\label{sub:a_model_of_the_user_s_behavior}

we need a probabilistic model of the user's behavior to predict its future activity.
In \name, the only data we collect and share, through the \squad overlay, are the availability times of each device among a \squad.
In our model, time is discretized, i.e. users periodically change the state availability of their devices in a predefined period.
We store the availability times in an ever-increasing \emph{sequence} $O=O_1, ..., O_i, ...$ of actions performed at every \emph{round}, that lasts a short period of time $T$. 
$d \in O_t$ thus means that the device $d$ was online from time $t$ to time $t+T$.
Our goal is to predict $O_{t+1}$ knowing $O_t$.

To this end, we model the user's behavior as a Hidden Markov Models (HMMs) of order one, with multiple discrete \emph{observable} processes (one per device) stored in $O$. 
The hidden process $S=S_1, ..., S_i, ...$ represents the user's locations, constituted of a set of $N$ potential locations (e.g. home, work or outside), $N$ being a user-defined parameter.
A HMM of order one is such that the hidden variable at time $t$, $S_t$, only depends on the hidden variable at $t-1$, $S_{t-1}$.
The observations at time $t$, $O_t$, depend on the current hidden variable only, $S_t$.

We first formally define our HMM, then show how to predict the future knowing the HMM, then finally present how to infer the model from the observable sequence only.

% In \name, we take interest in users that own several devices, and wish to privately exchange files with each other without revealing .
% To the best of our knowledge, no real-world traces of multi-devices usage over several days exist, as would be needed for the experimental evaluation of our system.
% For that reason, we propose a user behavioral model having the following features:

% \begin{itemize}
% 	\item Each user owns a variable amount of devices. We consider the following device types: mobile, portable, fixed, and server;
% 	\item The user travels between three ``locations'' according to a simple probabilistic model: her home, her workplace, and outside;
% 	\item She makes a different use of her devices depending on her location: at home, she will her laptop that at work; she cannot use her workstation at home.
% \end{itemize}

% To this end, we use a Hidden Markov Model (HMM) of order one, with multiple discrete observation processes. 
% The hidden Markovian process $S$ represents the user's locations, while the \emph{observable} process $O=O_1, \dots, \O_T$ represents the connection state of her devices (either connected or disconnected at any point in time).

% Such a statistical model is simplistic (e.g. it does not encapsulate date \& time nor location), but it is on purpose: simplicity is bliss.
% Given the lack of real-world data for our testbed, building a more complex and realistic user model would add no value to our proposal: 
% our goal is to see devices exhibiting frequent disconnections and reconnections (also called \emph{churn}).
% Our simple model being able to put extravagant stress on our system, it is sufficient to access \name's resilience.

\paragraph*{Formal definition} 

%We consider a single user, owning a set of $\mathcal{D}$ devices.
%Time is discretized \commentAL{Discretized/synchronous time needs more explanation}. Needs, and the devices' observations are independent: Alice can have her laptop and phone connected at the same time.
The hidden process $S=S_1,\dots,S_i, \dots$ is built from an alphabet of states $\mathcal{S}$, while the observable process $O=O_1, \dots, \O_i, \dots$ contains elements from the alphabet $\mathcal{O}$. We define a multivariate HMM $\lambda_N$ as follows:

$$\text{HMM}:\;\lambda_N=(\Pi, A, B)$$

where 
\begin{itemize}
	\item $N$ is the number of states in the system:
	$N = \left| \mathcal{S} \right|$;

	\item $\Pi=\left\{ \pi_i\right\}_{i\in\mathcal{S}}$ is the initial state distribution:\\
	$\pi_i=P[S_1=i]$;

	\item $A = \left\{ a_{i\,j}\right\}_{(i,j)\in\mathcal{S}^2}$ is the state transition matrix:\\
	$a_{i\,j}=P[S_t=j \mid S_{t-1}=i]$;

	\item $B = \left\{ b_{i\,k}\right\}_{(i,k)\in\mathcal{S}\times\mathcal{D}}$ is the matrix of event emission probabilities for each state:
	$b_{i\,k} = P[ k \in O_t \mid S_t = i]$.
\end{itemize}

In our case, the states $\mathcal{S}$ are the different locations $\mathcal{L}$ where the user is susceptible to go.
The events represent the devices availability, hence $\mathcal{O} = \mathcal{D}$, where $\mathcal{D}$ is the set of the user's devices.
Several devices can be available at the same time, such that $O_t$ is a set, and $d \in O_t$ means that device $d$ was available at time $t$. Devices' availability probabilities are independent.


% In \cref{fig:hmm}, we show an example HMM of a user's behavioral HMM, along with its graphical representation (the initial state distribution $\Pi$ was left out for simplicity). 
% The represented user possesses a phone and a laptop, that she carries around with her, a home computer, that is only accessible from her home, and a workstation, located at her workplace. She never forgets to turn off her fixed appliances before leaving.

% Figure~\ref{fig:sample_usage}, shows a possible trace of the user's behavior, using the parameters depicted in figure~\ref{fig:hmm}. 
% It reads the timeline of $o_{d}$ for each device $d$. On the bottom of the graph, the first letter of the user's location is shown at each time step.
% We see that devices connections depend on the user's location, and that any number of devices can be connected at the same time.

\paragraph*{Predicting future behavior} 
\label{para:predicting future behavior}
As already stated, devices want to predict whether they are likely to be available in the near future.
This information will be publicly available to enable the intelligent building of routes.

Because devices availability only depend on the users location, we can predict the devices availability in $i$ round $O_{t+i}$ given only the model $\lambda_N$ and the current user's location $S_t$. We first compute the probability that a device $d$ will be available next turn:

$$
P\left[ d \in O_{t} \mid S_{t-1} = s \right] = 
\sum\limits_{s' \in \mathcal{S}} 
a_{s\,s'} * b_{s'\,d}.
$$

It is the sum of the probabilities, for each state $s$, that the user switches to $s$ and uses her device.
Recursively, predicting $i$ turns in advance follows the same logic:

\begin{multline*}
P\left[ d \in O_{t+i} \mid S_{t} = s \right] = \\
\sum\limits_{s' \in \mathcal{S}}
P\left[ S_{t+1} = s' \mid S_t = s \right] * 
P\left[ d \in O_{t+i} \mid S_{t+1} = s'\right].
\end{multline*}

We show in section~\ref{sub:predictive_onion_routes_creation} that the prediction of devices' availability at $t+1$ is a good enough estimator of their availability state at $t+i$.
For that reason, devices only compute and publish $P\left[ d \in O_{t+1} \mid S_{t} = s \right]$.

\paragraph*{Inferring the model from the sequence of observations}

Given an initial estimate $\lambda_{N}^{(0)}$ of the model, and the sequence of observations $O$, the Baum-Welch algorithm uses Expectation-Maximization to iteratively compute the most likely $S^{(i)}$ and $\lambda_{N}^{(i)}$ until the probability of the observations using the estimated model falls below a predefined threshold: $P[O; \lambda_{N}^{(i)}] < \epsilon$.
Devices use this algorithm to infer their user's behavioral model from the observations.

It needs an initial model, though, with a predefined number of states $N$. 
$N$ is given by the user, and we set $\lambda_{N}^{(0)}$ to be a uniform model: probabilities of switching to each location are uniform, and all devices have a probability of being online of 0.5.

Baum-Welch usually requires a lot of data to fit the model $\lambda_N$ that generated $O$.
Indeed, $P[O; \lambda_{N}^{(i)}] < \epsilon$ does not mean that $\lambda_N \simeq \lambda_N^{(i)}$.
In our case, we do not care as long as the predictions using the estimated model, $P[O_{t+1} \mid S_t; \lambda_N^{(i)}]$, are close to the ground-truth, $P[O_{t+1} \mid S_t; \lambda_N]$.
%This will be evaluated in section~\ref{sub:devices_predictions_of_the_user_behavior}.